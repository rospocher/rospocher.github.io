@article{2025inf,
 abstract = {In this paper, we introduce a survey-based methodology to audit LLM-generated personas by simulating 200 US residents and collecting responses to socio-demographic questions in a zero-shot setting. We investigate whether LLMs default to standardized profiles, how these profiles differ across models, and how conditioning on specific attributes affects the resulting portrayals. Our findings reveal that LLMs often produce homogenized personas that underrepresent demographic diversity and that conditioning on attributes such as gender, ethnicity, or disability may trigger stereotypical shifts. These results highlight implicit biases in LLMs and underscore the need for systematic approaches to evaluate and mitigate fairness risks in model outputs.},
 article-number = {931},
 author = {Marco Bombieri and Marco Rospocher},
 bdsk-url-1 = {https://www.mdpi.com/2078-2489/16/11/931},
 bdsk-url-2 = {https://doi.org/10.3390/info16110931},
 date-added = {2025-10-26 11:04:37 +0100},
 date-modified = {2025-10-26 11:05:37 +0100},
 doi = {10.3390/info16110931},
 issn = {2078-2489},
 journal = {Information},
 number = {11},
 title = {Mining Impersonification Bias in LLMs via Survey Filling},
 volume = {16},
 year = {2025}
}
